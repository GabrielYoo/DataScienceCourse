Classification metrics
  Measuring model performance with accuracy
  Fraction of correctly classified samples
  Not always a useful matrics
  Class imbalance exaples:Emails
  Need more nuance matrics
Diagnosing classification predictions
  confusion matrix - precision, recall,F1 score
  High precision:not many real emails predicted as spam
  High recall: Predicted most spam emails correctly

Evaluating the performance of binary classifiers by computing a confusion matrix and generating a classification report.

# Import necessary modules
from sklearn.metrics import classification_report 
from sklearn.metrics import confusion_matrix

# Create training and test set
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)

# Instantiate a k-NN classifier: knn
knn = KNeighborsClassifier(n_neighbors=6)

# Fit the classifier to the training data
knn.fit(X_train,y_train)

# Predict the labels of the test data: y_pred
y_pred = knn.predict(X_test)

# Generate the confusion matrix and classification report
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
